{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e28f25d6-3b16-4b62-adc9-3ec13774d14e",
   "metadata": {},
   "source": [
    "## Pre-processing and Training Data Development\n",
    "\n",
    "The goal of the preprocessing work is to prepare your data for fitting models. If you\n",
    "identified any categorical features in your dataset in the EDA step, now is the time to\n",
    "create dummy features to allow for the inclusion of those features in your model\n",
    "development. Additionally, standardizing the features numeric magnitude and creating\n",
    "train and test data subsets happen in this step. You may want to save a version of your\n",
    "clean, preprocessed data frame as a CSV to access later.\n",
    "If you need a refresher about how to complete this work, review the work you did during\n",
    "the guided capstone and revisit the DSM Medium article .\n",
    "The following steps should be completed in a Jupyter Notebook.\n",
    "Goal: Create a cleaned development dataset you can use to complete the\n",
    "modeling step of your project.\n",
    "Steps:\n",
    "● Create dummy or indicator features for categorical variables\n",
    "● Standardize the magnitude of numeric features using a scaler\n",
    "● Split into testing and training datasets\n",
    "Review the following questions and apply them to your dataset:\n",
    "● Does my data set have any categorical data, such as Gender or day of the week?\n",
    "● Do my features have data values that range from 0 - 100 or 0-1 or both and more? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f06eca01-9ad1-40a3-8645-9c342d9c92fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import necesary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5621bcb3-df4a-460a-b307-1faea0d1a308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load cleaned dataset\n",
    "df = pd.read_csv('sentimentdataset_cleaned.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f627f42b-86a5-43df-9305-bc649b0867bb",
   "metadata": {},
   "source": [
    "Considerations for the \n",
    "\n",
    "Feature selection: Since we are simply attempting to evaluate the sentiment of a social media post, we only need to consider our text field which includes the combined raw text and hashtags, tokenized, and filtered for punctuation, emojis, and stand-alone digits. Other fields such as likes, date, and country can be ignored for the purposes of evaluating a predictive model for just the processed text.\n",
    "\n",
    "Scaling: Since there are no numeric features here and we only have one input parameter, feature scaling may not be necesary.\n",
    "\n",
    "Outliers: Since the text is an aggregation of social media posts, outliers shouldn't have a significant affect on the models as it might if the domain of focus was more narrow and or technical such as a physics research paper in an analysis of medical papers.\n",
    "\n",
    "Imbalanced datasets: In our case, we know that there is an imbalance of the three categories. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b5c947-a440-4046-85a2-b3ace7f76011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save our text as features, X and sentiment data as a target, y\n",
    "X = df['Text_Combined']\n",
    "y_v = df['Sentiment_VADER']\n",
    "y_tb = df['Sentiment_TextBlob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17bf8675-62a0-4da3-a0a3-2540af06bf8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split features and target into training and test sets\n",
    "X_vtrain, X_vtest, y_vtrain, y_vtest = train_test_split(X, y_v, test_size=0.2, random_state=123)\n",
    "X_tbtrain, X_tbtest, y_tbtrain, y_tbtest = train_test_split(X, y_tb, test_size=0.33, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f00b962-3e55-4fe6-86f4-6bded43462b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export training and test data\n",
    "X_vtrain.to_csv('X_vtrain.csv', index = False)\n",
    "X_tbtrain.to_csv('X_tbtrain.csv', index = False)\n",
    "y_vtrain.to_csv('y_vtrain.csv', index = False)\n",
    "y_tbtrain.to_csv('y_tbtrain.csv', index = False)\n",
    "X_vtest.to_csv('X_vtest.csv', index = False)\n",
    "X_tbtest.to_csv('X_tbtest.csv', index = False)\n",
    "y_vtest.to_csv('y_vtest.csv',index = False)\n",
    "y_tbtest.to_csv('y_tbtest.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
